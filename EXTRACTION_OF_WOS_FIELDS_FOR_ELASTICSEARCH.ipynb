{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import json\n",
    "import xmltodict\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "import xml.dom.minidom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentHead = {\"UID\":\"\",\n",
    "                \"publishedIn\":\"\",\n",
    "               \"docType\":\"\"}\n",
    "referenceInformation = {\"count\" : \"\",\n",
    "                       \"references\":[]}\n",
    "authorInformation = {\"count\" : \"\",\n",
    "                     \"authors\":[]}\n",
    "pub_info = {\"coverdate\":\"\",\n",
    "           \"has_abstract\":\"\",\n",
    "           \"issue\":\"\",\n",
    "           \"pubmonth\":\"\",\n",
    "           \"pubtype\":\"\",\n",
    "           \"pubyear\":\"\",\n",
    "           \"sortdate\":\"\",\n",
    "           \"volume\":\"\",\n",
    "           \"page_count\":\"\",\n",
    "           \"special_issue\":\"\"}\n",
    "abstract_info = {\"count\":\"\",\n",
    "           \"text\":\"\"}\n",
    "\n",
    "keywords_info = {\"count\":\"\",\n",
    "           \"keywords\":[]}\n",
    "\n",
    "addressInformation = {\"count\":\"\",\n",
    "                    \"address\":[]}\n",
    "normalized_language = {\"count\":\"\",\n",
    "                      \"language\":[]}\n",
    "fundingText = {'fund_text':\"\"}\n",
    "\n",
    "category_info={\"headings\":[],\n",
    "              \"subheadings\":[],\n",
    "              \"subjects\":[]}\n",
    "title_info={\"title\":[]}\n",
    "identifiers_info = {\"identifiers\":[]}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#connection to elasticsearch server\n",
    "es = Elasticsearch(\"http://localhost:9200\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createRecord(documentHead,referenceInformation,authorInformation,pub_info,abstract_info,keywords_info,addressInformation,normalized_language,fundingText,category_info,title_info,identifiers_info):\n",
    "    record = {\"UID\":documentHead[\"UID\"],\"publishedIn\":documentHead[\"publishedIn\"],\"docType\":documentHead[\"docType\"],\"title_info\":title_info,\"referenceInformation\":referenceInformation,\n",
    "              \"authorInformation\":authorInformation,\"pub_info\":pub_info,\"abstract\":abstract_info,\"keywords\":keywords_info,\"addressInformation\":addressInformation,\"normalized_languages\":normalized_language,\"fundingText\":fundingText,\"category_info\":category_info,\"identifiers_info\":identifiers_info}\n",
    "    return record\n",
    "def convertToList(aitem):    \n",
    "    if isinstance(aitem,dict):\n",
    "        aitem = [aitem]\n",
    "    return aitem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createWosItem(wosItem,aitem):\n",
    "    removedKeys = []    \n",
    "    for key in wosItem.keys():\n",
    "        if key in aitem.keys():\n",
    "            if isinstance(aitem[key], str):                    \n",
    "                wosItem[key] = aitem[key]\n",
    "            elif isinstance(aitem[key], dict):\n",
    "                wosItem[key] = aitem[key]['#text']\n",
    "        else:\n",
    "            removedKeys.append(key)              \n",
    "    for rkey in removedKeys:\n",
    "        wosItem.pop(rkey, None)            \n",
    "    return wosItem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingTitles(parseTitle,title_info):\n",
    "    titleList = []\n",
    "    for record in parseTitle:\n",
    "        addItem = {\"type\":\"\",\"text\":\"\"}\n",
    "        if record is not None:\n",
    "            addItem['type']=record[\"@type\"]\n",
    "            addItem['text']=record['#text']\n",
    "            titleList.append(addItem)\n",
    "    if(len(titleList)>0):\n",
    "        title_info['title']=titleList\n",
    "    return title_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingIdentifiers(parseIdentifiers,identifiers_info):\n",
    "    identifiersList = []\n",
    "    for record in parseIdentifiers:\n",
    "        addItem = {\"type\":\"\",\"value\":\"\"}\n",
    "        if record is not None:\n",
    "            #print(record)\n",
    "            addItem['type']=record[\"@type\"]\n",
    "            addItem['value']=record['@value']\n",
    "            identifiersList.append(addItem)\n",
    "    if(len(identifiersList)>0):\n",
    "        identifiers_info['identifiers']=identifiersList\n",
    "    return identifiers_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingAddress(parseAddresses,addressList):\n",
    "    for record in parseAddresses:\n",
    "        addItem = {\"addr_no\":\"\",\"full_address\":\"\",\"organizations\":\"\",\"suborganizations\":\"\",\"city\":\"\",\"state\":\"\",\"country\":\"\",\"zip\":\"\"}\n",
    "        if record is not None:  \n",
    "            addItem['addr_no'] = record['address_spec']['@addr_no']\n",
    "            addItem['full_address'] = record['address_spec']['full_address']\n",
    "\n",
    "            parseOrganiztion = convertToList(record['address_spec']['organizations'])\n",
    "            organizations =\"\"\n",
    "            for orgRec in parseOrganiztion:\n",
    "                if orgRec is not None:\n",
    "                    organizations+= orgRec['organization'][1]['#text']+\";\"\n",
    "                addItem['organizations']=organizations\n",
    "            \n",
    "            parseSuborganiztion = convertToList(record['address_spec']['suborganizations'])\n",
    "            suborganizations = \"\"\n",
    "            for orgRec in parseSuborganiztion:\n",
    "                if orgRec is not None:\n",
    "                    suborganizations+= orgRec['suborganization']+\";\"\n",
    "            addItem['suborganizations']=suborganizations\n",
    "            addItem['city'] = record['address_spec']['city']\n",
    "            addItem['state'] = record['address_spec']['state']\n",
    "            addItem['country'] = record['address_spec']['country']\n",
    "            addItem['zip'] = record['address_spec']['zip']['#text']\n",
    "            if addItem is not None: \n",
    "                addressList.append(addItem)\n",
    "    return addressList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingPublicationInfo(parsePubInfo,pub_info):\n",
    "    for record in parsePubInfo:\n",
    "        if record is not None:\n",
    "            pub_info['coverdate']=record['@coverdate']\n",
    "            pub_info['has_abstract']=record['@has_abstract']\n",
    "            pub_info['issue']=record['@issue']\n",
    "            pub_info['pubmonth']=record['@pubmonth']\n",
    "            pub_info['pubtype']=record['@pubtype']\n",
    "            pub_info['pubyear']=record['@pubyear']\n",
    "            pub_info['sortdate']=record['@sortdate']\n",
    "            pub_info['volume']=record['@volume']\n",
    "            pub_info['special_issue']=record['@special_issue']\n",
    "            pub_info['page_count']=record['page']\n",
    "    return pub_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractingCategoryInfo(parseCategory,category_info):\n",
    "    headingList = []\n",
    "    subheadingList =[]\n",
    "    subjectList = []\n",
    "    if(parseCategory is not None):\n",
    "        parseHeadings = convertToList(parseCategory['headings'])\n",
    "        if parseHeadings is not None:\n",
    "            for record in parseHeadings:\n",
    "                addItem = {\"count\":\"\",\"heading\":\"\"}\n",
    "                if(record is not None):\n",
    "                    addItem['count']=record['@count']\n",
    "                    addItem['heading']=record['heading']\n",
    "                    headingList.append(addItem)\n",
    "        \n",
    "        \n",
    "        parseSubHeadings = convertToList(parseCategory['subheadings'])\n",
    "        if parseSubHeadings is not None:\n",
    "            for record in parseSubHeadings:\n",
    "                addItem = {\"count\":\"\",\"heading\":\"\"}\n",
    "                if(record is not None):\n",
    "                    addItem['count']=record['@count']\n",
    "                    addItem['heading']=record['subheading']\n",
    "                    subheadingList.append(addItem)\n",
    "        parseSubject = convertToList(parseCategory['subjects']['subject'])\n",
    "        if parseSubject is not None:\n",
    "            #print(parseSubject)\n",
    "            #category_info['subjects_count']=parseSubject['@count']\n",
    "            for record in parseSubject:\n",
    "                addItem = {'ascatype': '', 'text': ''}\n",
    "                if record is not None:\n",
    "                    #record = json.loads(record)\n",
    "                    addItem['ascatype']=record['@ascatype']\n",
    "                    addItem['text']=record['#text']\n",
    "                    subjectList.append(addItem)\n",
    "        category_info['headings'] = headingList\n",
    "        category_info['subheadings'] = subheadingList\n",
    "        category_info['subjects'] = subjectList\n",
    "\n",
    "    return category_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "recordList = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WOS_RAW_20160108083942_DSSHPSH_0001.xml.gz\n",
      "/Users/rajeshpiryani/Desktop/wos/test/WOS_RAW_20160108083942_DSSHPSH_0001.xml.gz\n",
      "done for all files\n"
     ]
    }
   ],
   "source": [
    "for x in os.listdir('/Users/rajeshpiryani/Desktop/wos'):\n",
    "    for file in os.listdir(\"/Users/rajeshpiryani/Desktop/wos/\"+x):\n",
    "        if file.endswith(\"xml.gz\"):\n",
    "            print (file)\n",
    "            \n",
    "            input_filename = \"/Users/rajeshpiryani/Desktop/wos/\"+x+\"/\"+file\n",
    "            print (input_filename)\n",
    "            #input_filename = \"../../wos/WOS_RAW_20160108083942_DSSHPSH_0001.xml.gz\"\n",
    "            \n",
    "            totalRecord = 0\n",
    "            with gzip.open(input_filename, mode=\"rt\", encoding=\"utf-8\") as f:\n",
    "                xmlRecord = \"\"\n",
    "                for nr, line in enumerate(f):\n",
    "                    if(nr<3):continue #nr<2 for sample.xml.gz\" file and nr<3 for huge xml.gz file\n",
    "                    xmlRecord += line + \"\\n\"\n",
    "                    if line.strip() == \"</REC>\":\n",
    "                        #if(totalRecord==20):break\n",
    "                        totalRecord+=1\n",
    "                        #xmlRecord = xmlRecord.replace(\"pref=\\\"Y\\\"\",\"\")\n",
    "                        #print(\"PRcoessed Record \"+str(len(recordList)))\n",
    "                        data = xmltodict.parse(xmlRecord)\n",
    "                        es_doc_id = data['REC']['UID']\n",
    "                        rec_json = json.dumps(data['REC'])\n",
    "\n",
    "                        dataJ = json.loads(rec_json)            \n",
    "                        output_filename = \"output.json\"\n",
    "                        out_f = open(output_filename,'w')\n",
    "                        json.dump(dataJ,out_f)\n",
    "                        #print (dataJ['static_data']['fullrecord_metadata']['references']['reference'])\n",
    "                        #print(dataJ)\n",
    "                        documentHead['docType'] = dataJ['static_data']['summary']['doctypes']['doctype']\n",
    "                        referenceInformation['count'] = dataJ['static_data']['fullrecord_metadata']['references']['@count']\n",
    "                        authorInformation['count'] = dataJ['static_data']['summary']['names']['@count']\n",
    "                        addressInformation['count'] = dataJ['static_data']['fullrecord_metadata']['addresses']['@count']\n",
    "                        normalized_language['count'] = dataJ['static_data']['fullrecord_metadata']['normalized_languages']['@count']\n",
    "                        referenceList = []\n",
    "                        authorList = []         \n",
    "                        addressList = []\n",
    "                        #Building the references\n",
    "                        documentHead['UID'] = data['REC']['UID']\n",
    "                        #parseReferences = dataJ['static_data']['fullrecord_metadata']['references']['reference']\n",
    "                        \n",
    "                        #extracting Identifiers info\n",
    "                        try:\n",
    "                            parseIdentifiers = convertToList(dataJ['dynamic_data']['cluster_related']['identifiers']['identifier'])\n",
    "                            identifiers_info = extractingIdentifiers(parseIdentifiers,identifiers_info)\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        #extracting Title info\n",
    "                        try:\n",
    "                            parseTitle = convertToList(dataJ['static_data']['summary']['titles']['title'])\n",
    "                            title_info = extractingTitles(parseTitle,title_info)\n",
    "                        except:\n",
    "                            pass\n",
    "                        #extracting Funding Text\n",
    "                        try:\n",
    "                            parseFundingText = dataJ['static_data']['fullrecord_metadata']['fund_ack']\n",
    "                            if parseFundingText is not None:\n",
    "                                fundingText['fund_text']=parseFundingText['fund_text']['p']\n",
    "                                \n",
    "                                #documentHead['fundingText'] = parseFundingText['#text']\n",
    "                        except:\n",
    "                            pass\n",
    "                        \n",
    "                        #extracting normalized_languages\n",
    "                        try:\n",
    "                            parseNormalized_language=dataJ['static_data']['fullrecord_metadata']['normalized_languages']['language']\n",
    "                            if parseNormalized_language is not None:\n",
    "                                normalized_language['language']=parseNormalized_language['#text']\n",
    "                        except:\n",
    "                            pass\n",
    "                        #Extracting abstract_info\n",
    "                        try:\n",
    "                            parseAbstract = convertToList(dataJ['static_data']['fullrecord_metadata']['abstracts']['abstract'])\n",
    "                            for record in parseAbstract:\n",
    "                                if record is not None:\n",
    "                                    abstract_info['count']=record['abstract_text']['@count']\n",
    "                                    abstract_info['text']=record['abstract_text']['p']\n",
    "                                    #print(abstract_info)\n",
    "                        except:                \n",
    "                            pass\n",
    "                        \n",
    "                        #Extracting keywords_info\n",
    "                        try:\n",
    "                            parseKeywords = convertToList(dataJ['static_data']['fullrecord_metadata']['keywords']['keyword'])\n",
    "                            count = 0\n",
    "                            keywordsList = []\n",
    "                            for record in parseKeywords:\n",
    "                                if record is not None:\n",
    "                                    count+=1\n",
    "                                    keywordsList.append(record)\n",
    "                            if(len(keywordsList))>0:\n",
    "                                keywords_info['keywords']=keywordsList\n",
    "                            keywords_info['count']=count\n",
    "                            \n",
    "                        except:                \n",
    "                            pass\n",
    "                        \n",
    "                        #Extracting pub_info\n",
    "                        try:\n",
    "                            parsePubInfo = convertToList(dataJ['static_data']['summary']['pub_info'])\n",
    "                            pub_info = extractingPublicationInfo(parsePubInfo,pub_info)\n",
    "                        except:                \n",
    "                            pass\n",
    "                        \n",
    "                        #Extracting addresses\n",
    "                        try:\n",
    "                            parseAddresses = convertToList(dataJ['static_data']['fullrecord_metadata']['addresses']['address_name'])\n",
    "                            addressList = extractingAddress(parseAddresses,addressList)      \n",
    "                        except:                \n",
    "                            pass\n",
    "                        #Extracting category info\n",
    "                        try:\n",
    "                            parseCategory = dataJ['static_data']['fullrecord_metadata']['category_info']\n",
    "                            category_info = extractingCategoryInfo(parseCategory,category_info)      \n",
    "                        except:                \n",
    "                            pass\n",
    "                        #Extracting reference_info\n",
    "                        try:\n",
    "                            parseReferences = convertToList(dataJ['static_data']['fullrecord_metadata']['references']['reference'])\n",
    "                            for record in parseReferences:\n",
    "                                refItem = {\"uid\":\"\",\"citedAuthor\":\"\",\"year\":\"\",\"page\":\"\",\"volume\":\"\",\"citedTitle\":\"\",\"citedWork\":\"\",\"doi\":\"\"}\n",
    "                                if record is not None:                                            \n",
    "                                    refItem = createWosItem(refItem,record)\n",
    "                                    if refItem is not None: \n",
    "                                        referenceList.append(refItem)\n",
    "                        except:                \n",
    "                            pass\n",
    "                        \n",
    "                        try:\n",
    "                            parseAuthor = convertToList(dataJ['static_data']['summary']['names']['name']) \n",
    "\n",
    "                            for record in parseAuthor:\n",
    "                                authorItem = {\"@addr_no\":\"\",\"#seq_no\":\"\",\"full_name\":\"\",\"first_name\":\"\",\"last_name\":\"\",\"wos_standard\":\"\"}\n",
    "                                if record is not None:\n",
    "                                    authorItem = createWosItem(authorItem,record)\n",
    "                                    if authorItem is not None:\n",
    "                                        authorList.append(authorItem)\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "                        if len(referenceList)>0:\n",
    "                            referenceInformation['references'] = referenceList\n",
    "                        if len(authorList)>0:\n",
    "                            authorInformation['authors'] = authorList\n",
    "                        if(len(addressList))>0:\n",
    "                            addressInformation['address']=addressList\n",
    "                        wos_document = createRecord(documentHead,referenceInformation,authorInformation,pub_info,abstract_info,keywords_info,addressInformation,normalized_language,fundingText,category_info,title_info,identifiers_info)\n",
    "                        recordList.append(wos_document)\n",
    "\n",
    "                        if len(recordList) ==10000:\n",
    "                            print (\"Sending 10000 files to es\")\n",
    "                            helpers.bulk(es, recordList, index=\"wos\", doc_type=\"wos_record\")\n",
    "                            print (\"Done sending 10000 files to es\")\n",
    "                            recordList = []\n",
    "                        \n",
    "\n",
    "                        xmlRecord = \"\"\n",
    "                        #break\n",
    "                        \n",
    "print (\"done for all files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
